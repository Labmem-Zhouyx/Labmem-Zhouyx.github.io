<!DOCTYPE html>
<html lang="en">
<head>
	<title>Yixuan Zhou</title>

	<!-- Meta -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="Xiaoying Riley at 3rd Wave Media">
	<link rel="shortcut icon" href="images/favicon.ico">

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet">

	<!-- FontAwesome JS-->
	<script defer src="assets/fontawesome/js/all.min.js"></script>

	<!-- Theme CSS -->
	<link id="theme-style" rel="stylesheet" href="assets/css/devresume.css">

</head>

<body>
	<!-- DEMO ONLY -->
	<div class="main-wrapper">
		<div class="container px-3 px-lg-5">
			<article class="resume-wrapper mx-auto theme-bg-light p-5 mb-5 my-5 shadow-lg">

				<div class="resume-header">
					<div class="row align-items-center">
						<div class="resume-title col-12 col-md-6 col-lg-8 col-xl-9">
							<h2><font face="verdana">Yixuan Zhou (周逸轩)</font></h2>
							<div class="resume-tagline mb-3 mb-md-0">
								Shenzhen International Graduate School, Tsinghua University
							</div>
							<p class="mb-0">
								Human-Computer Speech Interaction Lab at Tsinghua University <a class="resume-link" href="https://thuhcsi.github.io/" target="_blank">(THUHCSI)</a>	
							</p>
						</div><!--//resume-title-->

						<div class="resume-contact col-12 col-md-6 col-lg-4 col-xl-3">
							<ul class="list-unstyled mb-0">
								<li class="mb-2"><i class="fas fa-envelope-square fa-fw fa-lg mr-2"></i><a class="resume-link" href="mailto:yx-zhou23@mails.tsinghua.edu.cn">yx-zhou23@mails.tsinghua.edu.cn</a></li>
								<li class="mb-2"><i class="fab fa-google fa-fw fa-lg mr-2"></i><a class="resume-link" href="https://scholar.google.com/citations?user=ZI_Cm1cAAAAJ&hl=zh-CN">Google Scholar</a></li>
								<li class="mb-2"><i class="fab fa-github fa-fw fa-lg mr-2"></i><a class="resume-link" href="https://github.com/Labmem-Zhouyx">Github</a></li>
								<li class="mb-0"><i class="fas fa-map-marker-alt fa-fw fa-lg mr-2"></i>Shenzhen, Guangdong, China</li>
							</ul>
						</div><!--//resume-contact-->
					</div><!--//row-->

				</div><!--//resume-header-->
				<hr>
				<div class="resume-intro py-3">
					<div class="media flex-column flex-md-row align-items-center">
						<img class="resume-profile-image mb-3 mb-md-0 mr-md-5 ml-md-0 rounded mx-auto" src="images/myresume.jpg" alt="image">
						<div class="col text-start">
							<p class="mb-0">
								I'm currently a PhD student at <a href="https://www.sigs.tsinghua.edu.cn/en/" target="_blank">Shenzhen International Graduate School, Tsinghua University
								(SIGS, THU)</a> in Shenzhen. My supervisor is <a href="https://www.sigs.tsinghua.edu.cn/wzy/main.htm" target="_blank">Prof. Zhiyong Wu</a>. Before that,
								I received my bachelor’s degree at 2020, in School of Information Science and Engineering from <a href="https://www.seu.edu.cn/" target="_blank">SouthEast University.</a>
								<br>My research interests include <b>Zero-Shot Voice Cloning</b>, <b>Expressive/Audiobook/Conversational Speech Synthesis</b>, etc. and now mainly focus on <b>Large-Scale Speech/Audio/Music Generation Model</b>.
							</p>
						</div><!--//media-body-->
					</div>
				</div><!--//resume-intro-->
				<hr>
				<div class="resume-body">
					<div class="row">
						<div class="resume-main col-12 col-lg-8 col-xl-9 pr-0 pr-lg-5">
							<section class="work-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">News</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list" style="list-style: outside;list-style-type: square;">
											<li> <b>[Sep 2025]</b> Open-source <b>VoxCPM-0.5B</b>[<a href = "https://github.com/OpenBMB/VoxCPM" target="_blank">GitHub</a>] as the project leader.</li>
											<li> <b>[Jul 2025]</b> One paper is accepted to ACMMM 2025.</li>
											<li> <b>[Mar 2025]</b> One paper is accepted to Interspeech 2025.</li>
											<li> <b>[Jan 2025]</b> Open-source <b>MiniCPM-o 2.6</b>[<a href = "https://github.com/OpenBMB/MiniCPM-o" target="_blank">GitHub</a>](<font color="#CC0033">Top on Github Trending and HuggingFace Trending</font>) as a main contributor in speech modality.</li>
											<li> <b>[Dec 2024]</b> One paper is accepted to ICASSP 2025.</li>
											<li> <b>[Nov 2024]</b> One paper is accepted to ISCSLP 2024.</li>
											<li> <b>[Sep 2024]</b> One paper is accepted to NeurIPS 2024.</li>
											<li> <b>[Jul 2024]</b> Three paper are accepted to ACMMM 2024, one as main conference (<font color="#CC0033">oral (4%)</font>) and two as workshop.</li>
											<li> <b>[Jun 2024]</b> One paper is accepted to Interspeech 2024.</li>
											<li> <b>[Apr 2024]</b> Two papers are accepted to ICASSP 2024.</li>
											<li> <b>[Oct 2023]</b> One paper is accepted to IEEE/ACM Transactions on Audio, Speech and Language Processing</li>
											<li> <b>[Jul 2023]</b> One paper is accepted to Interspeech 2023.</li>
											<li> <b>[Jun 2023]</b> One paper is recognized as the <font color="#CC0033">top 3%</font> paper accepted at ICASSP 2023.</li>
											<li> <b>[Sep 2022]</b> Three papers are accepted to Interspeech 2022.</li>
											<li> <b>[May 2022]</b> Two papers are accepted to ICASSP 2022.</li>
											<li> <b>[May 2021]</b> One paper is accepted to ICASSP 2021.</li>
										</ul>
									</div>
								</div><!--//item-->

							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Publications <a href='https://scholar.google.com/citations?user=ZI_Cm1cAAAAJ&hl=zh-CN'>[Google Scholar]</a></h3>

								<div class="item mb-3">
									<div class="item-content">
										<div class="item-content">
										<br>

										<font color="#39AB56"><b>2025:</b></font>
										<ul class="resume-list" style="list-style: outside;" >
											<li>
												<div class="resume-degree font-weight-bold">
													HarmoniVox: Painting Voices to Match the Avatar's Soul
												</div>
												<div class="resume-degree-org text-muted">
													Songtao Zhou, Xiaoyu Qin, <b>Yixuan Zhou</b>, Qixin Wang, Zeyu Jin, Zixuan Wang, Zhiyong Wu, Jia Jia
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ACMMM, 2025</font>
												</div>
											</li>	
											<li>
												<div class="resume-degree font-weight-bold">
													In This Environment, As That Speaker: A Text-Driven Framework for Multi-Attribute Speech Conversion
												</div>
												<div class="resume-degree-org text-muted">
													Jiawei Jin, Zhihan Yang, <b>Yixuan Zhou</b>, Zhiyong Wu
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Interspeech, 2025</font>
													[<a href = "https://www.isca-archive.org/interspeech_2025/jin25d_interspeech.pdf" target="_blank">Paper</a>]
												</div>
											</li>	
											<li>
												<div class="resume-degree font-weight-bold">
													DiffCSS: Diverse and Expressive Conversational Speech Synthesis with Diffusion Models
												</div>
												<div class="resume-degree-org text-muted">
													Weihao Wu, Zhiwei Lin, <b>Yixuan Zhou</b>, Jingbei Li, Rui Niu, Qinghua Wu, Songjun Cao, Long Ma, Zhiyong Wu
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2025</font>
													[<a href = "https://ieeexplore.ieee.org/document/10890208/" target="_blank">Paper</a>]
												</div>
											</li>
										</ul>
										<font color="#39AB56"><b>2025:</b></font>
										<ul class="resume-list" style="list-style: outside;" >
											<li>
												<div class="resume-degree font-weight-bold">
													The Codec Language Model-based Zero-Shot Spontaneous Style TTS System for CoVoC Challenge 2024
												</div>
												<div class="resume-degree-org text-muted">
													Shuoyi Zhou, <b>Yixuan Zhou</b>, Weiqing Li, Jun Chen, Runchuan Ye, Weihao Wu, Zijian Lin, Shun Lei, Zhiyong Wu
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ISCSLP, 2024</font>
													[<a href = "https://ieeexplore.ieee.org/abstract/document/10800681/" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													SongCreator: Lyrics-based Universal Song Generation
												</div>
												<div class="resume-degree-org text-muted">
													Shun Lei*, <b>Yixuan Zhou*</b>, Boshi Tang, Max WY Lam, Feng Liu, Hangyu Liu, Jingcheng Wu, Shiyin Kang, Zhiyong Wu, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">NeurIPS, 2024</font>
													[<a href = "https://openreview.net/forum?id=GlD9Juva5V" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixuan Zhou*</b>, Xiaoyu Qin*, Zeyu Jin, Shuoyi Zhou, Shun Lei, Songtao Zhou, Zhiyong Wu, Jia Jia
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ACM MM, 2024 <b>(Oral, 4%)</b></font>
													[<a href = "https://dl.acm.org/doi/abs/10.1145/3664647.3681680" target="_blank">Paper</a>]
													[<a href = "https://github.com/thuhcsi/VoxInstruct" target="_blank">GitHub</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													Multimodal Emotion Captioning Using Large Language Model with Prompt Engineering
												</div>
												<div class="resume-degree-org text-muted">
													Yaoxun Xu*, <b>Yixuan Zhou*</b>, Yunrui Cai, Jingran Xie, Runchuan Ye, Zhiyong Wu
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">MRAC workshop@ACM MM, 2024</font>
													[<a href = "https://dl.acm.org/doi/abs/10.1145/3689092.3689403" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													Robust Representation Learning for Multimodal Emotion Recognition with Contrastive Learning and Mixup
												</div>
												<div class="resume-degree-org text-muted">
													Yunrui Cai, Runchuan Ye, Jingran Xie, <b>Yixuan Zhou</b>, Yaoxun Xu, Zhiyong Wu
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">MRAC workshop@ACM MM, 2024</font>
													[<a href = "https://dl.acm.org/doi/abs/10.1145/3689092.3689418" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models
												</div>
												<div class="resume-degree-org text-muted">
													Weiqin Li, Peiji Yang, Yicheng Zhong, <b>Yixuan Zhou</b>, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Interspeech, 2024 </font>
													[<a href = "https://arxiv.org/abs/2407.13509" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													The THU-HCSI Multi-Speaker Multi-Lingual Few-Shot Voice Cloning System for LIMMITS'24 Challenge
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixuan Zhou</b>, Shuoyi Zhou, Shun Lei, Zhiyong Wu, Menglin Wu
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2024 </font>
													[<a href = "https://arxiv.org/abs/2404.16619" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts
												</div>
												<div class="resume-degree-org text-muted">
													Shun Lei*, <b>Yixuan Zhou*</b>, Liyang Chen, Dan Luo, Zhiyong Wu, Xixin Wu, Shiyin Kang, Tao Jiang, Yahui Zhou, Yuxing Han, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2024 </font>
													[<a href = "https://arxiv.org/abs/2309.11977" target="_blank">Paper</a>]
												</div>
											</li>
											
										</ul>

										<font color="#39AB56"><b>2023:</b></font>
										<ul class="resume-list" style="list-style: outside;" >

											<li>
												<div class="resume-degree font-weight-bold">
													MSStyleTTS: Multi-Scale Style Modeling with Hierarchical Context Information for Expressive Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													Shun Lei*, <b>Yixuan Zhou*</b>, Liyang Chen, Zhiyong Wu, Xixin Wu, Shiyin Kang, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">IEEE/ACM Transactions on Audio, Speech and Language Processing </font>
													[<a href = "https://arxiv.org/abs/2307.16012" target="_blank">Paper</a>]
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Towards Spontaneous Style Modeling with Semi-supervised Pre-training for Conversational Text-to-Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													Weiqin Li, Shun Lei, Qiaochu Huang, <b>Yixuan Zhou</b>, Zhiyong Wu, Shiyin Kang, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Interspeech, 2023 <b>(Oral)</b> </font>
													[<a href = "https://arxiv.org/abs/2304.12704" target="_blank">Paper</a>]
												</div>
											</li>
											
											<li>
												<div class="resume-degree font-weight-bold">
													Context-Aware Coherent Speaking Style Prediction with Hierarchical Transformers for Audiobook Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													Shun Lei*, <b>Yixuan Zhou*</b>, Liyang Chen, Zhiyong Wu, Shiyin Kang, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2023 <b>(Oral, Top 3% Paper)</b></font>
													[<a href = "https://arxiv.org/abs/2304.06359" target="_blank">Paper</a>]
												</div>
											</li>

										</ul>

										<font color="#39AB56"><b>2022:</b></font>
										<ul class="resume-list" style="list-style: outside;" >
											

											<li>
												<div class="resume-degree font-weight-bold">
													Content-Dependent Fine-Grained Speaker Embedding for Zero-Shot Speaker Adaptation in Text-to-Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixuan Zhou</b>, Changhe Song, Xiang Li, Luwen Zhang, Zhiyong Wu, Yanyao Bian, Dan Su, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Interspeech, 2022</font>
													[<a href = "https://arxiv.org/abs/2204.00990" target="_blank">Paper</a>]
													[<a href = "https://github.com/Labmem-Zhouyx/CDFSE_FastSpeech2" target="_blank">GitHub</a>]
												</div>
											</li>


											<li>
												<div class="resume-degree font-weight-bold">
													Enhancing Word-Level Semantic Representation via Dependency Structure for Expressive Text-to-Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixuan Zhou</b>*, Changhe Song*, Jingbei Li, Zhiyong Wu, Yanyao Bian, Dan Su, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Interspeech, 2022</font>
													[<a href = "https://arxiv.org/abs/2104.06835" target="_blank">Paper</a>]
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Towards Multi-Scale Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													Shun Lei*, <b>Yixuan Zhou*</b>, Liyang Chen, Hu Jiankun, Zhiyong Wu, Shiyin Kang, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Interspeech, 2022</font>
													[<a href = "https://arxiv.org/abs/2204.02743" target="_blank">Paper</a>]
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Towards Expressive Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis
												</div>
												<div class="resume-degree-org text-muted">
													Shun Lei, <b>Yixuan Zhou</b>, Liyang Chen, Zhiyong Wu, Shiyin Kang, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2022</font>
													[<a href = "https://arxiv.org/abs/2203.12201" target="_blank">Paper</a>]
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													A character-level span-based model for mandarin prosodic structure prediction
												</div>
												<div class="resume-degree-org text-muted">
													Xueyuan Chen*, Changhe Song*, <b>Yixuan Zhou</b>, Zhiyong Wu, Changbin Chen, Zhongqin Wu, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2022</font>
													[<a href = "https://ieeexplore.ieee.org/abstract/document/9747315" target="_blank">Paper</a>]
												</div>
											</li>

										</ul>

										<font color="#39AB56"><b>2021:</b></font>
										<ul class="resume-list" style="list-style: outside;" >

											<li>
												<div class="resume-degree font-weight-bold">
													Syntactic Representation Learning For Neural Network Based TTS with Syntactic Parse Tree Traversal
												</div>
												<div class="resume-degree-org text-muted">
													Changhe Song, Jingbei Li, <b>Yixuan Zhou</b>, Zhiyong Wu, Helen Meng
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICASSP, 2021</font>
													[<a href = "https://ieeexplore.ieee.org/abstract/document/9414671/" target="_blank">Paper</a>]
												</div>
											</li>
										</ul>
										</div>
									</div>
								</div>
							</section>
						</div>
						<aside class="resume-aside col-12 col-lg-4 col-xl-3 px-lg-4 pb-lg-4">
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Education</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">Ph.D. in Computer Science and Technology</div>
												<div class="resume-degree-org text-muted"><b>Tsinghua University</b></div>
												<div class="resume-degree-time text-muted">2022.09 - Present</div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">M.Eng. in Computer Technology (Successive)</div>
												<div class="resume-degree-org text-muted"><b>Tsinghua University</b></div>
												<div class="resume-degree-time text-muted">2020.09 - 2022.09</div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">B.Eng. in Information Technology</div>
												<div class="resume-degree-org text-muted"><b>SouthEast University</b></div>
												<div class="resume-degree-time text-muted">2016.09 - 2020.06</div>
											</li>
										</ul>
									</section>
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Experience</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">Speech & Multimodality Algorithm Intern</div>
												<div class="resume-degree font-weight-bold">Modelbest Inc.</div>
												<div class="resume-degree font-weight-bold"><b>MiniCPM-o project</b></div>
												<div class="resume-degree-org text-muted"><b>2024.08 - now </b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">Speech Algorithm Intern</div>
												<div class="resume-degree font-weight-bold">SAMI, ByteDance Inc.</div>
												<div class="resume-degree-org text-muted"><b>2022.09 - 2023.06</b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">Speech Algorithm Intern</div>
												<div class="resume-degree font-weight-bold">AI Lab, Tencent Inc.</div>
												<div class="resume-degree-org text-muted"><b>2021.05 - 2022.06</b></div>
											</li>
										</ul>
									</section>
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-3">
											Awards
										</h3>
										<ul class="list-unstyled resume-awards-list">
											<li class="mb-2">
												<div class="font-weight-bold">3rd in Constrained Track</div>
												<div class="text-muted">
													ISCSLP 2024 CoVoC Challenge
												</div>
											</li>
											<li class="mb-2">
												<div class="font-weight-bold">1st in Track-1, SMOS</div>
												<div class="text-muted">
													ICASSP 2024 LIMMITS'24 Challenge
												</div>
											</li>
											<li class="mb-2">
												<div class="font-weight-bold">Best Paper Award</div>
												<div class="text-muted">
													International PhdForum 2023
												</div>
											</li>
											<li class="mb-2">
												<div class="font-weight-bold">Bronze Medal</div>
												<div class="text-muted">
													The 2017 ICPC Asia Nanning Regional Contest
												</div>
											</li>
										</ul>
									</section>

									<section class="skills-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Collaborators</h3>
										<ul class="list-unstyled resume-lang-list">
											<ul class="list-unstyled pb-2">
												<li> <a href = "https://scholar.google.com/citations?user=7Xl6KdkAAAAJ&hl=zh-CN" target="_blank">Zhiyong Wu</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=_MZc2J8AAAAJ&hl=zh-CN" target="_blank">Changhe Song</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=kL2xyTYAAAAJ&hl=zh-CN" target="_blank">Shun Lei</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=mnCHk8EAAAAJ&hl=zh-CN" target="_blank">Shiyin Kang</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=sHbupL4AAAAJ&hl=zh-CN" target="_blank">Jingbei Li</a></li>
											
											</ul>
										</ul>
									</section>
								</aside>
							</div>
						</div>
					</article>

				</div>

			</div>


</body>
</html>
